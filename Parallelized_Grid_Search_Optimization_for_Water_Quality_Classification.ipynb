{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "57d041a6",
      "metadata": {
        "id": "57d041a6"
      },
      "source": [
        "#  Parallelized Grid Search Optimization for Water Quality Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3e8f629",
      "metadata": {
        "id": "b3e8f629"
      },
      "source": [
        "In aquatic systems, water quality is an important indicator of overall health. Numerous adverse effects can result from poor water quality, both on human health and the surrounding environment. So, this dataset is about water quality metrics and how to classify water potability. We have 3276 samples and 10 features"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75d4f240",
      "metadata": {
        "id": "75d4f240"
      },
      "source": [
        "X features:\n",
        "\n",
        "1-ph: pH of 1. water (0 to 14).\n",
        "\n",
        "2-Hardness: Capacity of water to precipitate soap in mg/L.\n",
        "\n",
        "3-Solids: Total dissolved solids in ppm.\n",
        "\n",
        "4-Chloramines: Amount of Chloramines in ppm.\n",
        "\n",
        "5-Sulfate: Amount of Sulfates dissolved in mg/L.\n",
        "\n",
        "6-Conductivity: Electrical conductivity of water in μS/cm.\n",
        "\n",
        "7-Organic_carbon: Amount of organic carbon in ppm.\n",
        "\n",
        "8-Trihalomethanes: Amount of Trihalomethanes in μg/L.\n",
        "\n",
        "9-Turbidity: Measure of light emiting property of water in NTU.\n",
        "\n",
        "Y feature:\n",
        "\n",
        "10-Potability : Indicates if water is safe for human consumption where 1 means Potable and 0 means Not potable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4495a222",
      "metadata": {
        "id": "4495a222"
      },
      "source": [
        "The link to the dataset: https://data.world/gymprathap/water-quality-dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d560909a",
      "metadata": {
        "id": "d560909a"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "085e9715",
      "metadata": {
        "scrolled": true,
        "id": "085e9715"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTETomek\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from threading import Thread, Lock\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from joblib import parallel_backend\n",
        "import time\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import os\n",
        "from joblib import Parallel, delayed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3105d05",
      "metadata": {
        "id": "d3105d05"
      },
      "source": [
        "### Read The File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bb7a81",
      "metadata": {
        "id": "c7bb7a81"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(r\"C:\\Users\\Noor\\Desktop\\parallel_pro\\water_potability.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d25c988",
      "metadata": {
        "id": "6d25c988"
      },
      "source": [
        "#### Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d6d5260",
      "metadata": {
        "id": "8d6d5260"
      },
      "outputs": [],
      "source": [
        "df2.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d89dd9",
      "metadata": {
        "id": "03d89dd9"
      },
      "source": [
        "### Fill the Missing Values with Median and Mean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a3d9bc0",
      "metadata": {
        "id": "4a3d9bc0"
      },
      "source": [
        "#### Filling pH Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9eb59df",
      "metadata": {
        "id": "c9eb59df"
      },
      "outputs": [],
      "source": [
        "pH_nan_1 = df2.query('Potability == 1')['ph'][df2['ph'].isna()].index\n",
        "df2.loc[pH_nan_1,'ph'] =df2.query('Potability == 1')['ph'][df2['ph'].notna()].median()\n",
        "\n",
        "pH_nan_0 = df2.query('Potability == 0')['ph'][df2['ph'].isna()].index\n",
        "df2.loc[pH_nan_0,'ph'] = df2.query('Potability == 0')['ph'][df2['ph'].notna()].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4a538a8",
      "metadata": {
        "id": "a4a538a8"
      },
      "source": [
        "#### Filling Sulfate Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b2b5dea",
      "metadata": {
        "id": "5b2b5dea"
      },
      "outputs": [],
      "source": [
        "Sulfate_nan_1 = df2.query('Potability == 1')['Sulfate'][df2['Sulfate'].isna()].index\n",
        "df2.loc[Sulfate_nan_1,'Sulfate'] =df2.query('Potability == 1')['Sulfate'][df2['Sulfate'].notna()].median()\n",
        "\n",
        "Sulfate_nan_0 = df2.query('Potability == 0')['Sulfate'][df2['Sulfate'].isna()].index\n",
        "df2.loc[Sulfate_nan_0,'Sulfate'] = df2.query('Potability == 0')['Sulfate'][df2['Sulfate'].notna()].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "592e7734",
      "metadata": {
        "id": "592e7734"
      },
      "source": [
        "#### Filling Trihalomethanes Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8718ff84",
      "metadata": {
        "id": "8718ff84"
      },
      "outputs": [],
      "source": [
        "Trihalomethanes_nan_1 = df2.query('Potability == 1')['Trihalomethanes'][df2['Trihalomethanes'].isna()].index\n",
        "df2.loc[Trihalomethanes_nan_1,'Trihalomethanes'] =df2.query('Potability == 1')['Trihalomethanes'][df2['Trihalomethanes'].notna()].median()\n",
        "\n",
        "Trihalomethanes_nan_0 = df2.query('Potability == 0')['Trihalomethanes'][df2['Trihalomethanes'].isna()].index\n",
        "df2.loc[Trihalomethanes_nan_0,'Trihalomethanes'] = df2.query('Potability == 0')['Trihalomethanes'][df2['Trihalomethanes'].notna()].median()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85c17df0",
      "metadata": {
        "id": "85c17df0"
      },
      "source": [
        "#### Count the Null Values After Filling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "083abf75",
      "metadata": {
        "id": "083abf75"
      },
      "outputs": [],
      "source": [
        "df2.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f62d1b",
      "metadata": {
        "id": "48f62d1b"
      },
      "source": [
        "#### Count the Potable and Non-potable Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d12c0cd9",
      "metadata": {
        "id": "d12c0cd9"
      },
      "outputs": [],
      "source": [
        "Potability=df2[\"Potability\"].value_counts()\n",
        "Potability"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595e31e4",
      "metadata": {
        "id": "595e31e4"
      },
      "source": [
        "## Train and Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0fe7c3",
      "metadata": {
        "id": "ff0fe7c3"
      },
      "outputs": [],
      "source": [
        "X = df2.drop('Potability',axis=1).values\n",
        "Y = df2['Potability'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7fb7fa9",
      "metadata": {
        "id": "f7fb7fa9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split (X,Y, random_state= 10,stratify=Y ,test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6029404b",
      "metadata": {
        "id": "6029404b"
      },
      "source": [
        "###  SMOTETomek for  Balancing the Data - Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3beef0",
      "metadata": {
        "id": "af3beef0"
      },
      "outputs": [],
      "source": [
        "#smote\n",
        "smote = SMOTETomek(random_state=10)\n",
        "x_train_smote, y_train_smote = smote.fit_resample(X_train, Y_train)\n",
        "print(\"X_train shape after smote: {} andn/ y_train shape after smote: {}\".format(x_train_smote.shape,y_train_smote.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f097e557",
      "metadata": {
        "id": "f097e557"
      },
      "outputs": [],
      "source": [
        "y_dist= pd.DataFrame(data=y_train_smote, index=range(y_train_smote.shape[0]),columns=[\"Potability\"])\n",
        "sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.title(\"Potability Class Distribution After SMOTE\")\n",
        "sns.countplot(x=\"Potability\", data=y_dist, palette='Paired');"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da2bcaf2",
      "metadata": {
        "id": "da2bcaf2"
      },
      "source": [
        "# First Algorithm: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e9b730",
      "metadata": {
        "id": "56e9b730"
      },
      "outputs": [],
      "source": [
        "#Define the RandomForestClassifier\n",
        "rf_params = {\n",
        "    'n_estimators': [ 100, 200],\n",
        "    'max_depth': [ 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': [ 'sqrt', 'log2']\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc0a012",
      "metadata": {
        "id": "6fc0a012"
      },
      "source": [
        "## Create a function to train and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22568afa",
      "metadata": {
        "id": "22568afa"
      },
      "outputs": [],
      "source": [
        "# Create a function to train a RandomForestClassifier on a subset of the data\n",
        "def train_rf(X_subset, y_subset, params):\n",
        "    rf = RandomForestClassifier(**params)\n",
        "    rf.fit(X_subset, y_subset)\n",
        "    return rf\n",
        "\n",
        "# Define a function to evaluate a model on the test set\n",
        "def evaluate_model(model, X_test, Y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(Y_test, y_pred)\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "382eeded",
      "metadata": {
        "id": "382eeded"
      },
      "source": [
        "## Non Parallel part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fa386b",
      "metadata": {
        "id": "94fa386b"
      },
      "outputs": [],
      "source": [
        "#  GridSearchCV\n",
        "grid_search_non_paralle_RF = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='accuracy' )\n",
        "\n",
        "# Measure time for non-parallelized grid search\n",
        "start_time_non_parallel = time.time()\n",
        "grid_search_non_paralle_RF.fit(x_train_smote, y_train_smote)\n",
        "end_time_non_parallel = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aed9099",
      "metadata": {
        "id": "9aed9099"
      },
      "outputs": [],
      "source": [
        "# Evaluate the non-parallelized model\n",
        "\n",
        "# Display the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best Hyperparameters (Non-parallel) of RF:\", grid_search_non_paralle_RF.best_params_)\n",
        "\n",
        "#print training time\n",
        "training_time_of_non_parallel_RF=end_time_non_parallel-start_time_non_parallel\n",
        "\n",
        "print(f\"\\nNon-parallelized model training time of RF= {training_time_of_non_parallel_RF} Sec\")\n",
        "\n",
        "RF_non_parallel = grid_search_non_paralle_RF.best_estimator_\n",
        "y_pred_non_parallel = RF_non_parallel.predict(X_test)\n",
        "\n",
        "accuracy_non_parallel_RF = accuracy_score(Y_test, y_pred_non_parallel)\n",
        "print(\"\\nAccuracy (Non-parallel) of RF:\", accuracy_non_parallel_RF)\n",
        "\n",
        "# Display the confusion matrix for the non-parallelized model\n",
        "confusion_matrix_non_parallel = confusion_matrix(Y_test, y_pred_non_parallel)\n",
        "print(\"\\nConfusion Matrix (Non-parallel) of RF:\")\n",
        "print(confusion_matrix_non_parallel)\n",
        "\n",
        "# Plot the confusion matrix for the non-parallelized model\n",
        "sns.heatmap(confusion_matrix_non_parallel, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix (Non-parallel) of RF\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9526ac75",
      "metadata": {
        "id": "9526ac75"
      },
      "source": [
        "## Parallel Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e896df",
      "metadata": {
        "id": "b6e896df"
      },
      "outputs": [],
      "source": [
        "#  GridSearchCV\n",
        "grid_search_paralle_RF = GridSearchCV(RandomForestClassifier(), rf_params, cv=5, scoring='accuracy',n_jobs=-1)\n",
        "# Train RandomForestClassifiers in parallel on each subset\n",
        "num_processors1 = os.cpu_count()\n",
        "\n",
        "start_time_parallel_RF = time.time()\n",
        "grid_search_paralle_RF.fit(x_train_smote, y_train_smote)\n",
        "rf_models_parallel = Parallel(n_jobs=-1)(\n",
        "    delayed(train_rf)(X_subset, y_subset, grid_search_paralle_RF.best_params_) for X_subset, y_subset in zip(np.array_split(x_train_smote, 4), np.array_split(y_train_smote, 4))\n",
        ")\n",
        "\n",
        "end_time_parallel_RF = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb93b53",
      "metadata": {
        "id": "5fb93b53"
      },
      "outputs": [],
      "source": [
        "# Evaluate the parallelized models\n",
        "accuracies_parallel = [evaluate_model(rf, X_test, Y_test) for rf in rf_models_parallel]\n",
        "\n",
        "# Display the best hyperparameters and their corresponding accuracy\n",
        "best_accuracy_parallel_RF = max(accuracies_parallel)\n",
        "print(\"\\nBest Hyperparameters (Parallel) of Rf:\", grid_search_paralle_RF.best_params_)\n",
        "\n",
        "#print training time\n",
        "training_time_of_parallel_RF=end_time_parallel_RF-start_time_parallel_RF\n",
        "\n",
        "print(f\"\\nTraining time of parallel RF = {training_time_of_parallel_RF} Sec\" )\n",
        "\n",
        "print(\"\\nBest Accuracy (Parallel) of RF:\", best_accuracy_parallel_RF)\n",
        "\n",
        "\n",
        "# Evaluate the parallelized models\n",
        "confusion_matrices_parallel = []\n",
        "for rf in rf_models_parallel:\n",
        "    y_pred_parallel = rf.predict(X_test)\n",
        "    cm = confusion_matrix(Y_test, y_pred_parallel)\n",
        "    confusion_matrices_parallel.append(cm)\n",
        "\n",
        "# Display the confusion matrix for the last model in the parallelized set\n",
        "print(\"\\nConfusion Matrix (Parallel)of RF:\")\n",
        "print(confusion_matrices_parallel[-1])\n",
        "\n",
        "# Plot the confusion matrix for the last model\n",
        "sns.heatmap(confusion_matrices_parallel[-1], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix (Parallel) of RF\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fec66394",
      "metadata": {
        "id": "fec66394"
      },
      "source": [
        "## Comparison between parallel and non-parallel  in RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1d0f8e",
      "metadata": {
        "id": "ec1d0f8e"
      },
      "outputs": [],
      "source": [
        "# Calculate Speed Up\n",
        "training_RF_speed_up = training_time_of_non_parallel_RF / training_time_of_parallel_RF\n",
        "\n",
        "# Calculate Efficiency\n",
        "training_RF_efficiency = training_RF_speed_up / num_processors1\n",
        "\n",
        "\n",
        "print(\"\\nBest Hyperparameters of (Parallel)  RF:\", grid_search_paralle_RF.best_params_)\n",
        "print(\"Best Hyperparameters of (Non-parallel)  RF:\", grid_search_non_paralle_RF.best_params_)\n",
        "\n",
        "print(\"\\nBest Accuracy of (Parallel)  RF:\", best_accuracy_parallel_RF)\n",
        "print(\"BestAccuracy of  (Non-parallel)  RF:\", accuracy_non_parallel_RF)\n",
        "\n",
        "print(f\"\\nTraining Time of (Parallelized)  RF: {training_time_of_parallel_RF} seconds\")\n",
        "print(f\"Training time of (Non-parallelized) RF= {training_time_of_non_parallel_RF} Sec\")\n",
        "\n",
        "\n",
        "print(f\"\\nTraining Speed Up: {training_RF_speed_up:.4f}\")\n",
        "\n",
        "print(f\"Training Efficiency: {training_RF_efficiency:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86133054",
      "metadata": {
        "id": "86133054"
      },
      "source": [
        "# Second Algorithm: Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc54bf40",
      "metadata": {
        "id": "bc54bf40"
      },
      "outputs": [],
      "source": [
        "# Define the SVM parameters\n",
        "svm_params  = {\n",
        "    'C': [ 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma':  [0.01,0.1],\n",
        "    'degree': [3,5]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71510668",
      "metadata": {
        "id": "71510668"
      },
      "source": [
        "## Create a function to train and evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5279f4c4",
      "metadata": {
        "id": "5279f4c4"
      },
      "outputs": [],
      "source": [
        "# Create a function to train an SVM on a subset of the data\n",
        "def train_svm(X_subset, y_subset, params):\n",
        "    svm = SVC(**params)\n",
        "    svm.fit(X_subset, y_subset)\n",
        "    return svm\n",
        "\n",
        "# Define a function to evaluate an SVM model on the test set\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2341244",
      "metadata": {
        "id": "c2341244"
      },
      "source": [
        "## Non Parallel part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e6a0cd",
      "metadata": {
        "id": "b2e6a0cd"
      },
      "outputs": [],
      "source": [
        "# Use GridSearchCV with Parallel and delayed for parallelized grid search\n",
        "grid_search_non_parallel_svm = GridSearchCV(SVC(), svm_params, cv=5, scoring='accuracy')\n",
        "\n",
        "# Measure time for non-parallelized grid search\n",
        "start_time_non_parallel_svm = time.time()\n",
        "grid_search_non_parallel_svm.fit(x_train_smote, y_train_smote)\n",
        "end_time_non_parallel_svm = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9422b839",
      "metadata": {
        "id": "9422b839"
      },
      "outputs": [],
      "source": [
        "# Evaluate the non-parallelized model\n",
        "\n",
        "# Display the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best Hyperparameters of (Non-parallel) SVM:\", grid_search_non_parallel_svm.best_params_)\n",
        "\n",
        "#print training time\n",
        "training_time_of_non_parallel_svm=end_time_non_parallel_svm-start_time_non_parallel_svm\n",
        "\n",
        "print(f\"\\nNon-parallelized model training time of svm  = {training_time_of_non_parallel_svm} Sec\")\n",
        "\n",
        "SVM_non_parallel = grid_search_non_parallel_svm.best_estimator_\n",
        "y_pred_non_parallel = SVM_non_parallel.predict(X_test)\n",
        "\n",
        "accuracy_non_parallel_SVM = accuracy_score(Y_test, y_pred_non_parallel)\n",
        "print(\"\\nAccuracy of (Non-parallel) svm:\", accuracy_non_parallel_SVM)\n",
        "\n",
        "# Display the confusion matrix for the non-parallelized model\n",
        "confusion_matrix_non_parallel = confusion_matrix(Y_test, y_pred_non_parallel)\n",
        "print(\"\\nConfusion Matrix of (Non-parallel) SVM:\")\n",
        "print(confusion_matrix_non_parallel)\n",
        "\n",
        "# Plot the confusion matrix for the non-parallelized model\n",
        "sns.heatmap(confusion_matrix_non_parallel, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix of (Non-parallel) SVM\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa8b6807",
      "metadata": {
        "id": "aa8b6807"
      },
      "source": [
        "## Parallel Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "204c0f79",
      "metadata": {
        "id": "204c0f79"
      },
      "outputs": [],
      "source": [
        "grid_search_paralle_svm = GridSearchCV(SVC(), svm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "#Train SVMs in parallel on each subset\n",
        "num_processors2 = os.cpu_count()\n",
        "\n",
        "start_time_parallel_svm = time.time()\n",
        "grid_search_paralle_svm.fit(x_train_smote, y_train_smote)\n",
        "\n",
        "svm_models_parallel = Parallel(n_jobs=-1)(\n",
        "    delayed(train_svm)(X_subset, y_subset, grid_search_paralle_svm.best_params_) for X_subset, y_subset in zip(np.array_split(x_train_smote, 4), np.array_split(y_train_smote, 4))\n",
        ")\n",
        "end_time_parallel_svm = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3781c799",
      "metadata": {
        "id": "3781c799"
      },
      "outputs": [],
      "source": [
        "# Evaluate the parallelized models\n",
        "accuracies_parallel = [evaluate_model(svm, X_test, Y_test) for svm in svm_models_parallel]\n",
        "\n",
        "# Display the best hyperparameters and their corresponding accuracy\n",
        "best_accuracy_parallel_SVM = max(accuracies_parallel)\n",
        "print(\"\\nBest Hyperparameters of (Parallel) SVM:\", grid_search_paralle_svm.best_params_)\n",
        "\n",
        "#print training time\n",
        "training_time_of_parallel_SVM=end_time_parallel_svm-start_time_parallel_svm\n",
        "print(f\"\\nparallelized model training time of SVM = {training_time_of_parallel_SVM} Sec\")\n",
        "\n",
        "print(\"\\nBest Accuracy of (Parallel)  SVM :\", best_accuracy_parallel_SVM)\n",
        "\n",
        "\n",
        "# Evaluate the parallelized models\n",
        "confusion_matrices_parallel = []\n",
        "for svm in svm_models_parallel:\n",
        "    y_pred_parallel = svm.predict(X_test)\n",
        "    cm = confusion_matrix(Y_test, y_pred_parallel)\n",
        "    confusion_matrices_parallel.append(cm)\n",
        "\n",
        "# Display the confusion matrix for the last model in the parallelized set\n",
        "print(\"\\nConfusion Matrix of (Parallel) SVM :\")\n",
        "print(confusion_matrices_parallel[-1])\n",
        "\n",
        "# Plot the confusion matrix for the last model\n",
        "sns.heatmap(confusion_matrices_parallel[-1], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix of  (Parallel) SVM \")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b105db",
      "metadata": {
        "id": "66b105db"
      },
      "source": [
        "## Comparison between parallel and non-parallel  in SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a784813",
      "metadata": {
        "scrolled": true,
        "id": "5a784813"
      },
      "outputs": [],
      "source": [
        "# Calculate Speed Up\n",
        "training_SVM_speed_up = training_time_of_non_parallel_svm / training_time_of_parallel_SVM\n",
        "\n",
        "# Calculate Efficiency\n",
        "training_SVM_efficiency = training_SVM_speed_up / num_processors2\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nBest Hyperparameters of (Parallel) SVM:\", grid_search_paralle_svm.best_params_)\n",
        "print(\"Best Hyperparameters of (Non-parallel) SVM:\", grid_search_non_parallel_svm.best_params_)\n",
        "\n",
        "print(\"\\nBest Accuracy of (Parallel)  SVM :\", best_accuracy_parallel_SVM)\n",
        "print(\"Best Accuracy of (Non-parallel) SVM:\", accuracy_non_parallel_SVM)\n",
        "\n",
        "print(f\"\\nTraining Time of (Parallelized)  SVM: {training_time_of_parallel_SVM} seconds\")\n",
        "print(f\"Training Time of (Non-parallelized)  SVM: {training_time_of_non_parallel_svm} Sec\")\n",
        "\n",
        "\n",
        "print(f\"\\nTraining Speed Up: {training_SVM_speed_up:.4f}\")\n",
        "\n",
        "print(f\"Training Efficiency: {training_SVM_efficiency:.4f}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35f365c",
      "metadata": {
        "id": "b35f365c"
      },
      "source": [
        "# Third Algorithm: Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3320e470",
      "metadata": {
        "id": "3320e470"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the Gradient Boosting parameters\n",
        "gb_params = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [5, 7],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [2, 4]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24296fe0",
      "metadata": {
        "id": "24296fe0"
      },
      "outputs": [],
      "source": [
        "# Create a function to train a GradientBoostingClassifier on a subset of the data\n",
        "def train_gb(X_subset, y_subset, params):\n",
        "    gb = GradientBoostingClassifier(**params)\n",
        "    gb.fit(X_subset, y_subset)\n",
        "    return gb\n",
        "\n",
        "# Define a function to evaluate a model on the test set\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d356d61",
      "metadata": {
        "id": "1d356d61"
      },
      "source": [
        "## Non paraller part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af6deb9e",
      "metadata": {
        "id": "af6deb9e"
      },
      "outputs": [],
      "source": [
        "# Use GridSearchCV with Parallel and delayed for parallelized grid search\n",
        "grid_search_non_parallel_gb = GridSearchCV(GradientBoostingClassifier(), gb_params, cv=5, scoring='accuracy')\n",
        "\n",
        "# Measure time for non-parallelized grid search\n",
        "start_time_non_parallel_gb = time.time()\n",
        "grid_search_non_parallel_gb.fit(x_train_smote, y_train_smote)\n",
        "end_time_non_parallel_gb = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b5d180",
      "metadata": {
        "id": "20b5d180"
      },
      "outputs": [],
      "source": [
        "# Evaluate the non-parallelized model\n",
        "\n",
        "# Display the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best Hyperparameters of (Non-parallel) GB:\", grid_search_non_parallel_gb.best_params_)\n",
        "\n",
        "#print training time\n",
        "training_time_of_non_paralle_GB=end_time_non_parallel_gb-start_time_non_parallel_gb\n",
        "print(f\"\\nNon-parallelized model training time of GB = {training_time_of_non_paralle_GB} Sec\")\n",
        "\n",
        "GB_non_parallel = grid_search_non_parallel_gb.best_estimator_\n",
        "y_pred_non_parallel = GB_non_parallel.predict(X_test)\n",
        "\n",
        "accuracy_non_parallel_GB = accuracy_score(Y_test, y_pred_non_parallel)\n",
        "print(\"\\nAccuracy of (Non-parallel) GB:\", accuracy_non_parallel_GB)\n",
        "\n",
        "# Display the confusion matrix for the non-parallelized model\n",
        "confusion_matrix_non_parallel = confusion_matrix(Y_test, y_pred_non_parallel)\n",
        "print(\"\\nConfusion Matrix of (Non-parallel) GB:\")\n",
        "print(confusion_matrix_non_parallel)\n",
        "\n",
        "# Plot the confusion matrix for the non-parallelized model\n",
        "sns.heatmap(confusion_matrix_non_parallel, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix of (Non-parallel) GB\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0410316",
      "metadata": {
        "id": "a0410316"
      },
      "source": [
        "## parallel part:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b27ed1",
      "metadata": {
        "id": "c3b27ed1"
      },
      "outputs": [],
      "source": [
        "# Train GradientBoostingClassifiers in parallel on each subset\n",
        "# Use GridSearchCV with Parallel and delayed for parallelized grid search\n",
        "grid_search_parallel_gb = GridSearchCV(GradientBoostingClassifier(), gb_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "num_processors3 = os.cpu_count()\n",
        "start_time_parallel_gb = time.time()\n",
        "\n",
        "grid_search_parallel_gb.fit(x_train_smote, y_train_smote)\n",
        "gb_models_parallel = Parallel(n_jobs=-1)(\n",
        "    delayed(train_gb)(X_subset, y_subset, grid_search_parallel_gb.best_params_) for X_subset, y_subset in zip(np.array_split(x_train_smote, 4), np.array_split(y_train_smote, 4))\n",
        ")\n",
        "end_time_parallel_gb = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "caea6c26",
      "metadata": {
        "id": "caea6c26"
      },
      "outputs": [],
      "source": [
        "# Evaluate the parallelized models\n",
        "accuracies_parallel = [evaluate_model(gb, X_test, Y_test) for gb in gb_models_parallel]\n",
        "\n",
        "# Display the best hyperparameters and their corresponding accuracy\n",
        "best_accuracy_parallel_GB = max(accuracies_parallel)\n",
        "print(\"\\nBest Hyperparameters of (Parallel) GB:\", grid_search_parallel_gb.best_params_)\n",
        "\n",
        "#print training time\n",
        "training_time_of_parallel_GB=end_time_parallel_gb-start_time_parallel_gb\n",
        "\n",
        "print(f\"\\nparallelized model training time of GB = {training_time_of_parallel_GB} Sec\")\n",
        "\n",
        "print(\"\\nBest Accuracy of (Parallel) GB :\", best_accuracy_parallel_GB)\n",
        "\n",
        "\n",
        "# Evaluate the parallelized models\n",
        "confusion_matrices_parallel = []\n",
        "for gb in gb_models_parallel:\n",
        "    y_pred_parallel = gb.predict(X_test)\n",
        "    cm = confusion_matrix(Y_test, y_pred_parallel)\n",
        "    confusion_matrices_parallel.append(cm)\n",
        "\n",
        "# Display the confusion matrix for the last model in the parallelized set\n",
        "print(\"\\nConfusion Matrix of (Parallel) GB :\")\n",
        "print(confusion_matrices_parallel[-1])\n",
        "\n",
        "# Plot the confusion matrix for the last model\n",
        "sns.heatmap(confusion_matrices_parallel[-1], annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix of (Parallel) GB \")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a5b89c3",
      "metadata": {
        "id": "1a5b89c3"
      },
      "source": [
        "## Comparison between parallel and non-parallel  in GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a236fd6e",
      "metadata": {
        "id": "a236fd6e"
      },
      "outputs": [],
      "source": [
        "# Calculate Speed Up\n",
        "training_GB_speed_up = training_time_of_non_paralle_GB / training_time_of_parallel_GB\n",
        "\n",
        "# Calculate Efficiency\n",
        "training_GB_efficiency = training_GB_speed_up / num_processors3\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nBest Hyperparameters of (Parallel) GB:\", grid_search_parallel_gb.best_params_)\n",
        "print(\"Best Hyperparameters of (Non-parallel) GB:\", grid_search_non_parallel_gb.best_params_)\n",
        "\n",
        "print(\"\\nBest Accuracy of (Parallel) GB:\", best_accuracy_parallel_GB)\n",
        "print(\"Best Accuracy of (Non-parallel) GB:\", accuracy_non_parallel_GB)\n",
        "\n",
        "print(f\"\\nTraining Time of (Parallelized) GB: {training_time_of_parallel_GB} seconds\")\n",
        "print(f\"Training Time  of (Non-parallelized)GB: {training_time_of_non_paralle_GB} seconds\")\n",
        "\n",
        "\n",
        "print(f\"\\n Training Speed Up: {training_GB_speed_up:.4f}\")\n",
        "\n",
        "print(f\"Training Efficiency: {training_GB_efficiency:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0228ad37",
      "metadata": {
        "id": "0228ad37"
      },
      "outputs": [],
      "source": [
        "# Plotting the speed up the results\n",
        "models = ['GB', 'SVM', 'RF']\n",
        "durations = [training_GB_speed_up, training_SVM_speed_up, training_RF_speed_up]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(models, durations, color=['blue', 'green', 'Red'])\n",
        "ax.set_ylabel('Training Time (seconds)')\n",
        "ax.set_title('Training Speedup Comparison')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29d5c63",
      "metadata": {
        "id": "c29d5c63"
      },
      "outputs": [],
      "source": [
        "# Plotting the results of efficiency\n",
        "models = ['GB', 'SVM', 'RF']\n",
        "durations = [training_GB_efficiency, training_SVM_efficiency, training_RF_efficiency]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(models, durations, color=['blue', 'green', 'Red'])\n",
        "ax.set_ylabel('Training Time (seconds)')\n",
        "ax.set_title('Training efficiency Comparison')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4_oCkeUugt4"
      },
      "source": [
        "This code was done by group AI7-1 for ARTI 503. Parallel AI7-1 course.\n",
        "\n",
        "Prepared for Dr. Naya Nagy.\n",
        "\n",
        "Group Members:\n",
        "- Joury Alzayat\n",
        "- Noor Aljashi\n",
        "- Abrar Sebiany\n",
        "- Manar Alsayed\n"
      ],
      "id": "n4_oCkeUugt4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}